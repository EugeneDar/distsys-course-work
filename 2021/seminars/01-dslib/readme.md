# Модель распределенной системы и учебный фреймворк

Для закрепления знаний, полученных на курсе, и развития практических навыков вы будете выполнять домашние задания. На семинарах мы будем знакомиться с каждым заданием, разбирать его требования, повторять и давать дополнительные материалы по теме задания, отвечать на ваши вопросы в ходе работы над заданием, а также разбирать его после срока сдачи.

## Задания и тестирование распределенных систем

Задания на курсе будут двух типов. Первый тип — реализация распределенных систем/приложений с использованием реальных технологий, например gRPC. Второй тип — реализация распределенных систем в рамках учебного фреймворка [dslib](https://github.com/osukhoroslov/dslib), имитирующего сеть и отказы. Заданий второго типа будет больше, поэтому сегодня мы поговорим о том, почему так сделано и как устроен этот фреймворк.

Мотивация заданий первого типа понятна — это опыт создания реальных приложений и использования технологий, которые применяются в индустрии. Однако проверить корректность работы таких приложений очень сложно в силу недетерминированного характера распределенных систем. От одного выполнения нашей системы к другому могут меняться порядок прихода сообщений, возникающие отказы, внешние воздействия и т.д. Запустив приложение один раз и получив корректный результат мы не можем быть уверены в том, что так будет всегда. Ошибка в реализации может проявляться в крайне редко возникающих, но, тем не менее, возможных ситуациях. Смоделировать все такие ситуации на реальной системе воспроизводимым образом крайне сложно. А поймав ошибку во время работы приложения, сложно воспроизвести потом приведшее к ней выполнение системы. 

Мы еще вернемся по ходу курса к тому, как тестировать распределенные приложения, в том числе надежным и воспроизводимым образом. Пока главное осознать, что это крайне непростая задача, требующая поддержки со стороны используемой программной инфраструктуры, и во многих реальных системах тесты не гарантируют корректность реализации. См. ссылки в конце семинара.

Одна из главных целей нашего курса — научить вас писать корректно работающие распределенные системы, осознавая при этом все возможные риски и ошибки. Для этого важно исчерпывающим и воспроизводимым образом тестировать ваши решения, что в случае заданий первого типа, как мы выяснили, проблематично. Поэтому эти задания мы будем использовать для знакомства и практики с реальными технологиями. А более сложные с точки зрения требований к корректности задания мы будем писать на базе фреймворка, позволяющего моделировать и воспроизводить при тестировании все "интересные" ситуации. Что-то вроде тренажера-симулятора, на котором отрабатывают навыки пилоты самолётов.

## Модель распределенной системы

Начать знакомство с фреймворком dslib стоит с используемой в нём модели распределенной системы. Как и в любой модели в ней оставлены наиболее важные для нас особенности изучаемых систем (отказы сети, например), а несущественные и слишком низкоуровневые детали (например, передача пакетов в сети) отброшены.

Мы будем использовать довольно простую, естественную и часто используемую модель распределенной системы. Система моделируется как набор _узлов (node)_, взаимодействующих друг с другом путём обмена _сообщениями_. С каждым узлом связан процесс, обрабатывающий входящие сообщения в соответствии с описанной программистом логикой. В процессе обработки сообщения узел может изменять свое состояние, отправлять сообщения другим узлам и выполнять другие описанные далее действия. Обработка сообщений узлом происходит строго последовательно в порядке их получения. Нет потоков и связанных с ними проблем, код узла по определению потокобезопасен, прямого доступа к его внутреннему состоянию у других узлов нет. Описанная модель узла близка к известной [модели акторов](https://en.wikipedia.org/wiki/Actor_model), примерами реализации которой для распределенных систем являются язык [Erlang](https://en.wikipedia.org/wiki/Erlang_(programming_language)) и фреймворк [Akka](https://en.wikipedia.org/wiki/Akka_(toolkit)).

Сообщения между узлами передаются через сеть. Модель сети, в зависимости от её настроек, может вносить задержку при передаче сообщений и реализовывать основные виды *сетевых отказов* — терять сообщения, переупорядочивать или дублировать их. Также можно моделировать более сложные виды отказов: полное отключение некоторого узла от сети, недоступность сети между парой узлов или в некотором направлении, разделение сети на несколько изолированных компонент (network partition). Некоторые виды сетевых отказов, такие как искажение передаваемых сообщений или появление сообщений "из воздуха", сейчас не реализованы. 

Помимо отказов сети важно также моделировать *отказы узлов*. Полный отказ (падение) узла моделируется аналогично полному отключению узла от сети. Отказ узла с последующим восстановлением (перезапуск) моделируется путем повторной инициализации узла со сбросом его состояния.

Помимо передачи сообщений по сети, узлы могут получать и отправлять _локальные сообщения_. Эти сообщения позволяют моделировать взаимодействие системы с внешними сущностями, например пользователями, и общаться с узлами из тестов. Локальные сообщения надежно доставляются в пределах узла, минуя сеть и связанные с ней задержки и отказы.

Также узлы могут отправлять себе напоминания в виде _таймеров_. При создании таймера указывается его имя и промежуток времени, через который он должен сработать. По истечении заданного времени узлу направляется уведомление о срабатывании таймера.

У каждого узла есть локальные часы. Также есть понятие глобального времени, к которому привязаны все события в системе (см. далее). Локальные часы могут расходиться и дрейфовать относительно глобального времени. Пока в dslib это не моделируется, и узлы могут читать глобальное время.

## Симуляция

Выполнение распределенной системы в dslib реализовано как пошаговая *симуляция* (более точно - [discrete event simulation](https://en.wikipedia.org/wiki/Discrete-event_simulation)). Каждый шаг соответствует наступлению и обработке некоторого _события_ (получению сообщения, отправке сообщения, срабатыванию таймера). С каждым событием связано глобальное время его наступления. Времена событий отправки сообщения и срабатывания таймера определяются тривиально. Время получения сообщения вычисляется как время отправки + задержка сети, в том числе случайная. События обрабатываются по очереди в порядке их времен путем вызова кода узла или сети. В результате обработки события могут генерироваться новые события. Например, получение сообщения может привести к отправке новых сообщений, а отправка сообщения приводит к его получению (с заданной задержкой) или отбрасыванию (если сеть ненадежна).

Важно, что порядок событий однозначно определяется настройками симуляции — параметрами сети, random seed и т.д. Иными словами, в отличие от реальной системы выполнение в симуляторе является _детерминированным_ — оно не будет меняться от запуска к запуску, мы можем контролировать и воспроизводить его. Путем задержек и отбрасывания событий мы можем реализовать произвольное возможное выполнение распределенной системы в рамках описанной модели, в том числе такое, которое сложно поймать в реальной системе.

Также нетрудно заметить, что при симуляции не требуется выполнять систему в реальном времени — вместо того, чтобы "спать" до наступления следующего события, можно сразу "перевести" глобальные часы вперед и перейти к его обработке. Это позволяет заметно ускорить тестирование.

## Пример

Рассмотрим пример, на котором разберем как пишутся и тестируются распределенные системы в учебном фреймворке. У нас будет очень простая система, состоящая из двух узлов — _клиента_ и _сервера_. Клиент отправляет сообщения PING на сервер, а сервер отвечает на них сообщениями PONG. Сообщения содержат в себе строковое поле `value`. Сервер вставляет в ответ значение `value` из сообщения клиента.   

В папке `ping-pong` есть несколько реализаций. Для начала откроем `basic.py` и посмотрим как устроены реализации `PingClient` и `PingServer`. Они реализуют интерфейс `Node`, [определенный](../../dslib/python/dslib.py) в dslib. Изучим методы этого интерфейса и классы `Message` и `Context`. 

### Интерфейс dslib для Python

Методы `on_local_message()` и `on_message()` предназначены для приема и обработки узлом локальных и сетевых сообщений соответственно. Сообщения описываются классом `Message` - у сообщения есть тип и содержимое в виде словаря со строковыми ключами, с которым можно работать через методы `Message`. В реализации системы можно использовать сообщения произвольных типов и структуры. В заданиях часть сообщений будет специфицирована, а часть надо будет определять самому. Метод `on_timer()` предназначен для обработки таймеров, он вызывается в момент срабатывания ранее установленного таймера. Во все методы `Node` передается объект типа `Context`, он предназначен для взаимодействия с симулируемым окружением. Через контекст можно узнать текущее время, отправить сообщение, установить или отменить таймер, сгенерировать случайное число. Узлы в системе идентифицируются с помощью уникальных строковых id, назначаемых при добавлении узла в систему (см. далее). Эти идентификаторы передаются при отправке (в `ctx.send()`) и приеме (в `on_message()`) сообщения. Без знания id узла отправить ему сообщение нельзя.

### Реализация узлов

Далее посмотрим как реализованы `PingClient` и `PingServer` в `basic.py`. Инициализация узлов (содержимое конструкторов) определяется в зависимости от системы. В данном случае мы хотим, чтобы и клиенту и серверу передавались их id (скорее для порядка, в реализации они нигде не используются) и клиенту передавался id сервера, чтобы клиент мог отправлять ему сообщения. В `on_local_message()` клиент реализует обработку локальных сообщений — при получении сообщения PING он направляет его серверу. Это будет наш способ инициировать выполнение системы. В `on_message()` клиент реализует обработку сообщений от сервера — при получении ответного сообщения PONG он пересылает его локально. Это будет наш способ проверить, что выполнение завершено корректно (ответ получен). Сервер принимает только сообщения из сети, в методе `on_message()` при получении сообщения PING он создает сообщение PONG и отправляет его обратно клиенту. Видно, что при этом сервер копирует поле `value` из исходного сообщения. Таймеры в этой реализации не используются.

### Тестирование

Теперь разберемся как запускать и тестировать нашу систему в dslib. Тесты и сам фреймворк написаны на языке Rust, а Python используется только для описания логики узлов. Поэтому для начала необходимо [установить Rust](https://www.rust-lang.org/tools/install). Далее скачайте в папку семинара код dslib: `git clone https://github.com/osukhoroslov/dslib`.

Примеры тестов находятся в папке `ping-pong/test`. Перейдите в эту папку и выполните команду `cargo run -- -help`. Тесты должны скомпилироваться и выдать справку по запуску.

Запустим простейший тест, который создает систему из пары узлов и инициирует выполнение, передав клиенту локальное сообщение: `cargo run -- -i ../basic.py -t run`. Тест выводит трассу выполнения системы в виде списка событий в порядке их наступления, с указанием времени и описания события.

Для сдачи заданий по курсу вам не потребуется изучать Rust. Достаточно только базового понимания синтаксиса и основных конструкций языка (см. ссылки в конце семинара), а также как реализуются тесты на dslib. Самим писать тесты в заданиях не требуется (однако если вы увидите, что наших тестов недостаточно, то вы можете придумать и описать в произвольной форме сценарии, которые не покрывают наши тесты, и получить за это бонусные баллы).

#### Устройство тестов

Посмотрим как устроены тесты в нашем примере, для этого откроем `test/src/main.rs`. В `main()` происходит считывание параметров командной строки, настройка фабрик для создания узлов по их реализациям на Python, настройка и запуск тестов. Под `UTILS` находятся вспомогательный код, используемый тестами. Структура `TestConfig` используется для описания параметров теста, а функция `build_system()` для создания нашей системы из клиента и сервера. Под `TESTS` находятся сами тесты в отдельных функциях. 

Мы запускали тест из `test_run()`, в нём собирается система и клиенту отправляется локальное сообщение PING, после чего с помощью метода `step_until_no_events()` запускается пошаговое выполнение системы до тех пор, пока есть события. После обмена сообщениями между клиентом и сервером, события закончатся и выполнение завершится. В данном тесте мы ничего не проверяем и всегда возвращаем в конце `Ok(true)`.

Теперь рассмотрим тест в `test_result()`. Он похож на предыдущий, но после выполнения системы мы также проверяем, вернул ли клиент локально ответное сообщение от сервера. Для этого мы читаем все локальные сообщения, которые отправил клиент, с помощью `sys.read_local_messages()` и проверяем, что сообщение одно и оно имеет ожидаемый тип и содержимое. Проверки выполняются с помощью макроса `assume!`, который возвращает результат типа `Result<bool, String>` - по сути или `true` (проверка пройдена) или строку с указанным сообщением об ошибке. Оператор `?` в конце позволяет досрочно выйти из функции в случае ошибки, вернув сообщение о ней в `TestResult`. Если же все проверки прошли, то мы дойдем до конца теста и вернем `Ok(true)`. Кроме того, в начале теста мы вызываем `sys.set_drop_rate()`, передавая значение из конфига. Этот параметр задает вероятность потери сообщения сетью во время доставки. По умолчанию он равен 0, то есть сеть является надежной. Но, как видно из `main()`, мы также запускаем этот тест со значением 0.5, моделируя ненадежную сеть.

Запустим сначала этот тест с надежной сетью: `cargo run -- -i ../basic.py -t result_reliable`. Наша реализация проходит его. Попробуйте изменить код реализации так, чтобы тест не проходил.

#### Зависимость результатов от random seed

Теперь запустим тест с ненадежной сетью: `cargo run -- -i ../basic.py -t result_unreliable`. Реализация проходит тест. Но значит ли это, что в ней нет проблем? Попробуем запустить тест, изменив random seed: `cargo run -- -i ../basic.py -t result_unreliable -s 12345`. Теперь третий тест не проходит из-за того, что PING теряется и не доходит до сервера. Какое ещё выполнение может привести к ошибке в этом тесте? Чтобы увидеть его, измените seed на `12345678`.

Рассматриваемый тест выглядит ненадежным — он сильно зависит от значения seed и может пропускать интересующие нас ситуации и ошибки, а подбирать seed руками неудобно. Один из вариантов повысить вероятность поймать ошибку — смоделировать обработку не одного, а нескольких запросов. См. тест в `test_10results()`. Запустим этот тест: `cargo run -- -i ../basic.py -t 10results_unreliable`. Ошибку удалось поймать уже со второй попытки. В общем случае при большом количестве попыток такой подход неплохо работает, но 100% гарантии поймать все проблемы он не дает. Посмотрим как гарантированно воспроизвести нужный нам ситуации.

#### Воспроизведение нужных ситуаций в тестах

Для гарантированной потери сообщения PING мы можем в начале сделать сеть полностью ненадежной (drop rate = 1), а через некоторое время, чтобы дать системе возможность завершить выполнение, сделаем её надежной. См. тест в `test_drop_ping()`, запустить его можно передав `-t drop_ping`. Перед тем, как сделать сеть надежной, мы делаем 10 шагов в симуляторе с помощью `sys.steps(10)`.

Для гарантированной потери сообщения PONG надо сделать сеть полностью ненадежной только после того, как PING дошел до сервера. Для этого в начале надо сделать 2 шага — обработка локального сообщения клиентом и обработка отправки сообщения PING сетью. После этого можно установить drop rate = 1, сделать несколько шагов и как раньше сделать сеть снова надежной. См. тест в `test_drop_pong()`, запустить его можно передав `-t drop_pong`. 

Аналогичного предыдущим двум тестам эффекта можно достичь временно отключив сеть между клиентом и серверов в одном из направлений. Как это сделать показано в `test_drop_ping2()` и `test_drop_pong2()`. При этом реализация второго теста становится проще. Запустим эти версии тестов и проверим, что их выполнение аналогично версиям с изменением drop rate.

#### Использование таймеров

Реализация из `basic.py` не работает в ненадежной сети. Попробуем починить её с помощью таймеров — после отправки PING клиент будет устанавливать таймер, при срабатывании которого проверять получил ли он ответ от сервера, если нет — то повторно отправлять PING. Если ответ получен, то клиент будет отменять таймер. Данная реализация находится в `retry.py`. Проверим, что она проходит все ранее рассмотренные тесты: `cargo run -- -i ../retry.py`.

#### Тест с уникальными запросами

У нас остался еще один тест `test_10results_unique()`. В нём используется еще одна настройка модели сети в dslib, позволяющая смоделировать случайную задержку (и, тем самым, переупорядочивание) сообщений. В вызове метода `sys.set_delays()` мы передаем минимальное и максимальное значения задержки. Далее в тесте мы отправляем клиенту несколько запросов, но теперь с уникальным содержимым `value`. На каждый запрос PING мы ожидаем получить ответ PONG с таким же содержимым. 

Запустим тест: `cargo run -- -i ../retry.py -t 10results_unique`. Реализация не проходит его, хотя сеть надежна. В чем причина? Запустим тест с ненадежной сетью: `cargo run -- -i ../retry.py -t 10results_unique_unreliable`. Почему этот тест проходит, если закомментировать `sys.set_delays()`? Как можно починить реализацию, чтобы она проходила тест в обоих случаях?

## Полезные ссылки

### Тестирование и симуляция распределенных систем

- [FoundationDB: Simulation and Testing](https://apple.github.io/foundationdb/testing.html)
- [Testing Distributed Systems w/ Deterministic Simulation](https://www.youtube.com/watch?v=4fFDFbi3toc)
- [FoundationDB or: How I Learned to Stop Worrying and Trust the Database](https://www.youtube.com/watch?v=OJb8A6h9jQQ)

### Rust

- [17 Resources to Help You Learn Rust in 2021](https://serokell.io/blog/learn-rust)
- [Rust For Systems Programmers](https://github.com/nrc/r4cppp)